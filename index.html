<!DOCTYPE html>
<html lang="en" dir="ltr">
  <head>
    <meta charset="utf-8">
    <link href="css/style.css" rel="stylesheet" type="text/css">
    <title>Xiangpeng Yang | Home</title>
  </head>
  <body id="top">
    <header>
      <nav>
        <ul>
          <li class="selected"><a href="#top">Home</a></li>
        </ul>
      </nav>
    </header>

    <div class="wrapper">
      <div class="section header-bar" id="about">
        <img src="images/yxp.jpg" class="avatar" alt="Xiangpeng Yang portrait">
        <div class="profile-meta">
          <h1>Xiangpeng Yang</h1>
          <div class="meta-line">Ph.D. Student, University of Technology Sydney (UTS)</div>
          <div class="meta-line">Generative AI · Video Generation · Vision &amp; Language · Multi-modal Learning</div>
          <div class="social-links">
            <a href="mailto:Xiangpeng.Yang@student.uts.edu.au">Email</a> /
            <a href="assets/cv/CV_xiangpeng.pdf" target="_blank">CV</a> /
            <a href="https://scholar.google.com/citations?user=reiIeYMAAAAJ" target="_blank">Google Scholar</a> /
            <a href="https://github.com/knightyxp" target="_blank">GitHub</a> /
            <a href="https://www.linkedin.com/in/xiangpeng-yang-a422851b2" target="_blank">LinkedIn</a> /
            <a href="https://x.com/Ayden_Yang_" target="_blank">Twitter</a>
          </div>
          <div>
            <span class="pill">Sydney, Australia</span>
            <span class="pill">Open to collaboration</span>
          </div>
        </div>
      </div>

      <div class="section" id="bio">
        <div class="section_header"><p><b>Biography</b></p></div>
        <p>
          Hi, I'm Xiangpeng. I am currently a Ph.D. student at the <a href="https://www.uts.edu.au/" target="_blank" style="color: #007d51;">University of Technology Sydney (UTS)</a>.
        </p>
        <p>
          My research interests involve <strong>Generative AI</strong>, <strong>Video Generation</strong>, and <strong>Multi-modal Learning</strong>.
          Specifically, I focus on video world models, video generation, and multi-modal foundation models.
        </p>
        <p>
          Looking ahead, I am deeply motivated to build unified video models capable of jointly understanding dynamic visual environments and generating coherent future content within a single framework. I believe this direction is a crucial step toward world models, where systems can reason about and interact with the physical world through continuous video understanding and prediction.
        </p>
        <p style="color: #d32f2f; font-weight: 500;">
          I am currently seeking research intern opportunities. If there are suitable positions available, please feel free to reach out. Thank you!
        </p>
      </div>

      <div class="section" id="news">
        <div class="section_header"><p><b>News</b></p></div>
        <ul class="list-unstyled">
          <li><strong>[12/2025]</strong> We Release the <a href="https://github.com/knightyxp/VideoCoF" target="_blank">Code</a> and <a href="https://huggingface.co/XiangpengYang/VideoCoF" target="_blank">Model</a> of <a href="https://arxiv.org/abs/2512.07469" target="_blank"><strong>VideoCoF</strong></a>.</li>
          <li><strong>[07/2025]</strong> Gave an invited talk at <strong>Sydney AI Meet-Up</strong>.</li>
          <li><strong>[01/2025]</strong> VideoGrain is accepted to <strong>ICLR 2025</strong>.</li>
          <li><strong>[12/2023]</strong> DGL is accepted to <strong>AAAI 2024</strong>.</li>
        </ul>
      </div>

      <div class="section" id="publications">
        <div class="section_header"><p><b>Selected Publications</b></p></div>
        <ul class="pub-list">
          <li class="pub-item">
            <div class="pub-image">
              <video width="250" autoplay loop muted playsinline style="border-radius: 12px; object-fit: cover;">
                <source src="images/videocof.mp4" type="video/mp4">
                Your browser does not support the video tag.
              </video>
            </div>
            <div class="pub-content">
              <div class="pub-title">Unified Video Editing with Temporal Reasoner</div>
              <div class="meta"><strong>Xiangpeng Yang</strong>, Ji Xie, Yiyuan Yang, Min Xu, Qiang Wu</div>
              <div class="meta" style="margin-bottom: 6px;"><strong>ArXiv</strong> (2025)</div>
              <div class="meta" style="margin-bottom: 12px; font-weight: 500;"><strong>TL;DR</strong>: Seeing, Reasoning, then Editing, A Unified Framework Reasoning over Video Content before Editing.</div>
              <div class="pub-links">
                <a href="https://arxiv.org/abs/2512.07469" target="_blank">ArXiv</a>
                <a href="https://videocof.github.io/" target="_blank">Project</a>
                <a href="https://github.com/knightyxp/VideoCoF" target="_blank">Code</a>
                <a href="https://huggingface.co/papers/2512.07469" target="_blank">HF page</a>
                <a href="https://www.youtube.com/watch?v=XrYj0Qmc49w" target="_blank">Video</a>
                <a href="https://mp.weixin.qq.com/s/e0X_0oF46oYJNqyAI3qetQ" target="_blank">media[机器之心]</a>
                <a href="https://github.com/knightyxp/VideoCoF" target="_blank">
                  <img src="https://img.shields.io/github/stars/knightyxp/VideoCoF?style=social" alt="GitHub Stars" class="github-badge">
                </a>
              </div>
            </div>
          </li>
          <li class="pub-item">
            <div class="pub-image">
              <video width="250" autoplay loop muted playsinline style="border-radius: 12px; object-fit: cover;">
                <source src="images/videograin.mp4" type="video/mp4">
                Your browser does not support the video tag.
              </video>
            </div>
            <div class="pub-content">
              <div class="pub-title">VideoGrain: Modulating Space-Time Attention for Multi-Grained Video Editing</div>
              <div class="meta"><strong>Xiangpeng Yang</strong>, Linchao Zhu, Hehe Fan, Yi Yang</div>
              <div class="meta" style="margin-bottom: 6px;"><strong>The International Conference on Learning Representations (ICLR)</strong>, 2025</div>
              <div class="meta" style="margin-bottom: 12px; font-weight: 500;"><strong>TL;DR</strong>: The first work propose Multi-Grained Video Editing, including Class, Instance and Part-level</div>
              <div class="pub-links">
                <a href="https://arxiv.org/abs/2502.17258" target="_blank">Paper</a>
                <a href="https://knightyxp.github.io/VideoGrain_project_page/" target="_blank">Project</a>
                <a href="https://github.com/knightyxp/VideoGrain" target="_blank">Code</a>
                <a href="https://huggingface.co/papers/2502.17258" target="_blank">HF Page</a>
                <a href="https://x.com/_akhaliq/status/1894254599223017622" target="_blank">media(ak)</a>
                <a href="https://x.com/Gradio/status/1894328911154028566" target="_blank">media(gradio)</a>
                <a href="https://github.com/knightyxp/VideoGrain" target="_blank">
                  <img src="https://img.shields.io/github/stars/knightyxp/VideoGrain?style=social" alt="GitHub Stars" class="github-badge">
                </a>
              </div>
            </div>
          </li>
          <li class="pub-item">
            <div class="pub-image"><img src="images/dgl.png" alt="DGL"></div>
            <div class="pub-content">
              <div class="pub-title">DGL: Dynamic Global-Local Prompt Tuning for Text-Video Retrieval</div>
              <div class="meta"><strong>Xiangpeng Yang</strong>, Linchao Zhu, Xiaohan Wang, Yi Yang</div>
              <div class="meta" style="margin-bottom: 6px;"><strong>AAAI Conference on Artificial Intelligence (AAAI)</strong>, 2024</div>
              <div class="meta" style="margin-bottom: 12px; font-weight: 500;"><strong>TL;DR</strong>: Training only 0.83 MB parameters to achieve better performance than full finetuning.</div>
              <div class="pub-links">
                <a href="https://arxiv.org/abs/2401.10588v1" target="_blank">Paper</a>
                <a href="https://github.com/knightyxp/DGL" target="_blank">Code</a>
                <a href="https://underline.io/lecture/91847-dgl-dynamic-global-local-prompt-tuning-for-text-video-retrieval" target="_blank">Video</a>
                <a href="https://github.com/knightyxp/DGL" target="_blank">
                  <img src="https://img.shields.io/github/stars/knightyxp/DGL?style=social" alt="GitHub Stars" class="github-badge">
                </a>
              </div>
            </div>
          </li>
        </ul>
      </div>

      <div class="section" id="experience">
        <div class="section_header"><p><b>Industry Experience</b></p></div>
        <ul class="list-unstyled">
          <li><strong>Baidu Research</strong> — Aug 2022 – Mar 2023 (Beijing)</li>
          <li><strong>ByteDance AI Lab</strong> — May 2021 – Sep 2021 (Beijing)</li>
        </ul>
      </div>

      <div class="section" id="invited-talks">
        <div class="section_header"><p><b>Invited Talks</b></p></div>
        <ul class="list-unstyled">
          <li><strong>[06/2025]</strong> "Multimodal SSMs, Multimodal Reasoning, and Multi-Grained Video Editing" at Twelve Labs, hosted by James Le (<a href="https://www.youtube.com/watch?v=7WGkNSU5vsI" target="_blank">video</a>).</li>
          <li><strong>[03/2025]</strong> "VideoGrain: Exploration and Application of Multi-Grained Video Editing Based on Diffusion Models" at Qingke AI (<a href="https://qingkeai.online/archives/ZktwYaEY" target="_blank">video</a>).</li>
        </ul>
      </div>

      <div class="section" id="service">
        <div class="section_header"><p><b>Academic Service</b></p></div>
        <ul class="list-unstyled">
          <li>Regular Reviewer: CVPR, ICLR, ICML, NeurIPS, ICCV, ECCV</li>
        </ul>
      </div>
      <div class="section" id="visitor-map" style="max-width:350px;margin:20px auto;">
        <div class="section_header" style="text-align:center;"><p><b>Visitor Map</b></p></div>
        <div style="max-width:350px;margin:0 auto;">
          <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=8CHv5jVdPeWo_2Em-WvYCHMm3h-ln9vb2idY8HTijHE&cl=ffffff&w=300"></script>
        </div>
      </div>
    </div>

    <footer style="padding:6px;margin-top:16px;">
      <div style="text-align:center;padding:0;color:#666;font-size:13px;">
        &copy; 2025 Xiangpeng Yang
      </div>
    </footer>
  </body>
</html>